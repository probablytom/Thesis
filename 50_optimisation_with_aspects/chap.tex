\chapter{Simulation Optimisation with Aspect Orientation}\label{chap:exp1_simulation_optimisation}

With a game deployed to experiment participants and a dataset of empirical play
collected, it was possible to determine optimal play in any game state. This
entirely separate body of work is documented in another student's PhD
thesis\inline{Cite William's PhD thesis}. This dataset leads to
further research. If we understand how players \emph{should} play, and we have
data to indicate how they \emph{do} play, we can investigate how real-world
players might be modelled. 

\section{Aims}\label{sec:aop_simulation_optimisation_aims}

Aspect orientation's use in previous simulation and modelling efforts have
typically focused on the use of aspects to compose model or simulation
details\inline{There must be tons of good citations for aspects being used to
compose together a simulation / model}. Critics of aspect orientation note that
the act of process composition makes visually understanding codebases difficult,
and so ensuring that a simulation properly models real-world behaviour is made
trickier with the introduction of aspect orientation. However, aspect
orientation might instead be used to \emph{augment} an existing model, by
rethinking what aspects are used to represent.

An alternative use of aspects would be to first build a non-aspect-oriented
model of \emph{expected} behaviour, and separately build aspects which describe
deviations from this. For example, one might more realistically simulate safety
procedures by first producing an idealised, ``naive'' model of what employees
are expected to do, and separately model alterations to prescribed behaviour as
an employee's boredom, expectation that checks and balances are unneccesary
wastes of their time, and so on --- effectively, separating out models of
degraded modes\cite{johnson2007degradedmodes}.

Previous research on the use of aspect orientation to model degraded modes
adopted the traditionally claimed benefit of aspect orientation: separation of
cross-cutting concerns, allowing for a greater reusability of
codebases\cite{wallis2018caise}. A repository of cross-cutting concerns in
socio-technical simulation such as boredom was developed as a library to be
applied to any future models\cite{fuzzimoss_repo}. However, aspects used in
simulation have no intrinsic need to represent concerns that are cross-cutting.
Indeed, whether they can be accurately used to represent cross-cutting concerns
in simulation is the topic addressed in \inline{Add a cross-reference to the
chapter on cross-cutting concern simulation accuracy when it exists}. Aspects
might instead be used to represent \emph{amendments to processes} which deviate
from an expected norm, in this case represented by the idealised model aspects
are applied to.

To more concretely relate this to the experiment at hand: play of RPGLite can be
modelled as players matchmaking, picking characters, and then mutually taking
turns until one player's characters are entirely expired. Once a player's
characters are dead, new matches can be made. This can continue indefinitely.
Lacking a heuristic to select next moves or characters, players might be
modelled as picking random moves. However, heuristics for move selection can be
added to the naive model of play by way of augmenting the processes already
defined through aspects. This approach can be of significant utility in both
modelling player behaviour and accurately modelling different players:

\begin{enumerate}
    \item Different players might use their own unique heuristics to model play.
    Each player's behaviour is therefore well described by separating what play
    ``looks like'' to what makes a given player play differently to their peers.
    \item Different players might lean more heavily on different heuristics, or
    mixes thereof. Play might be characterised by reliance on experience, on
    recent games, on knowledge of an opponent, and so on; these different
    variables can be expected to be weighted differently by each player, adding
    complexity to the code which models this individualised play.
    \item A modeller might discover a new idea for a heuristic long after
    developing an original concept for a model. The easiest methods for amending
    the original model should require the least rewriting of original code. Due
    to the impact of \pointno{2}, ideal architectures for an approach such as
    this should require these heuristics to be defined entirely separately to
    the base model.
\end{enumerate}

Considering \pointno{1}, \pointno{2}, and \pointno{3}, architectures and
paradigms which enable separation of concerns are well-suited to defining
alternative approaches to play. Some architectural approaches such as mixins or
plugin design patterns might support this structure well, but they typically
rely on language features (in the case of mixins) or knowledge of software
engineering (in the case of design patterns). Aspect orientation is typically
provided to developers as a framework or runtime in a language (such as
AspectJ\cite{aspectj_intro} or PROSE\cite{popovici2002PROSE}) and can require
minimal architectural understanding to use: concepts are simple, and the effort
of composition is alleviated by the supporting framework or runtime.

The approach makes little use of aspect orientation's significant contribution
--- cross-cutting concerns --- as whether behaviour cross-cuts different parts
of a codebase is not of interest in this use case. Instead, aspect orientation
is treated as a composition mechanism with a reasonably low degree of technical
knowledge required.

\subsection{PyDySoFu Suitability}\label{subsec:optimisation_with_aspects_usingpdsf}
Some aspect orientation frameworks do not adequately achieve this requirement.
For example, the most influential framework, AspectJ, requires the use of
language extensions to define integrate aspect
orientation\cite{AspectJLanguageAndTools}, and similar additional complexity is
added in seemingly every alternative framework, through the use of bespoke
virtual machines, compilers, translators, or
languages\cite{rajan2006nu_towardsAO_invocation,popovici2003JITaspects,AspectCplusplusDesignImpl,baker2002maya}.

PyDySoFu, however, requires very little additional knowledge to use. Its design
prioritises simplicity and a shallow learning curve that makes its adoption by
researchers without a software engineering background feasible: \inline{maybe
cut this list of reasons PyDySoFu is fantastic...}

\begin{itemize}
    \item PyDySoFu is implemented as a pure-python library, meaning that it can
    be installed through Python's package manager (pip) and imported like any
    other Python library. No additional supporting infrastructure is required.
    \item Aspects in PyDySoFu are simple functions which take as arguments
    whichever pieces of information are pertinent for the function's use as an
    aspect\footnote{For example, an ``encore'' aspect which is woven after a
    target procedure returns will be provided that target's return value.}.
    \item To weave a PyDySoFu aspect requires only a method call, which returns a
    \lstinline{callable} which unweaves that aspect.
    \item Defining PyDySoFu pointcuts requires only a regular expression
    matching a method name. This can apply to a wide range of join points if
    required, but where method names are provided directly, the join point is
    made clear.
    \item Additional clarity over where aspects \emph{can} be woven is
    introduced by PyDySoFu's transparent weaving of aspect hooks, mitigating
    some of aspect orientation's most prominent criticisms.
\end{itemize}

PyDySoFu therefore satisfies the requirements of this work well: it offers
composition of procedures outside of the scope of an original codebase, makes
what is being composed where clear to a programmer, and makes no significant
changes to Python as a language (thereby requiring users to specialise in fewer
tools). 


\subsection{Proposed Experiment}\label{subsec:optimisation_with_aspects_experiment}

Aspect orientation's use as a composition tool for model components makes sense
in principle, but it is unclear whether the addition of behaviours to a naive
model would make the model more ``realistic''. Furthermore, changes to a model
could alter its representation so as to weaken its mimicry of the system it
simulates; adding behaviours could make it \emph{less} realistic. The
fundamental issue at play is that it is unclear whether the changes made would
properly represent what might be empirically observed. While PyDySoFu's design
makes understanding what is being composed simpler than other aspect orientation
frameworks, a composed model under this paradigm is still split across multiple
areas of a codebase, making a visual assessment of whether a model accurately
reflects the intended behaviour impractical. It is therefore important to
demonstrate the efficacy of PyDySoFu and the modelling paradigm it introduces,
by confirming the realism of a model to which behavioural variation is applied.

We can confirm whether aspects can realistically represent changes to a naive
understanding of the real world by comparing their output against empirical
data. For example, if a such a model of behaviour in a system outputs data which
correlates poorly against empirically collected data, a change to that system
would make it more realistic if it improved this correlation, and could be said
to be realistic if the generated data appeared sufficiently ``close'' to the
empirical dataset --- which here means that the correlation between the two is
of statistical significance. Such a change can be aspect-oriented. Therefore, we
can see the application of aspects as the application of packages of potential
improvements to a base model, which can be verified by way of comparison to
known-good datasets.

This is the basis of the experiments in this thesis.

With datasets collected empirically on RPGLite's play, we can build a naive
model of play and aspects to apply that should realistically model data from
players. This can be used to answer the question:

\begin{researchquestion}
    Can aspect-oriented models be said to exhibit realism?
\end{researchquestion}

% To answer this question, a naive model of play is produced, and aspects
% developed which encapsulate different play styles so as to compare empirically
% sourced datasets against both its aspect-augmented and unaltered counterparts.
% The following subsections detail the naive model developed and aspects applied
% to this model.

To answer this question, a naive model of play is produced. Aspects are
developed which model learning within the system defined by the naive system.
The synthetic datasets produced by models with naive or aspect-applied models
can be compared to an empirical dataset sourced from real-world players of the
game, and their similarity compared. 

``Naive'' is used here to describe a model which does not encode any
understanding of the players of the game being modelled. Traits such as
learning, distraction, or aptitude for similar games are irrelevant to the naive
model. We need a naive model to demonstrate the effectiveness of an
aspect-oriented alternative: we can measure how closely it reflects empirical
data, and compare this against the same measurement drawn from another model
with behavioural variations encoded using aspects. A closer match from our
aspect-oriented model would demonstrate that the technique can enhance a model's
realism. Our naive model also provides a null hypothesis: if no improved
similarity is observed, the technique brought no improvement to the model's
realism. No measurable difference indicates that weaving behavioural variations
as aspects has no impact on a model's realism.

\inline{Write a little here on the learning aspects.}

\inline{Flesh this out as a brief wrap-up of our experimental technique. The end
of our ``naive'' model explanation might be useful to move down here / rework
into this para.} Contrasting the similarity of the empirical dataset to both
naive and aspect-applied datasets\ldots{} This discussion is provided so as to
provide context for the following sections; experimental design is discussed in
more depth in \cref{sec:optimisation_with_aspects_experimental_design}. 


\section{Naive Model}\label{sec:optimisation_with_aspects_naivemodel}

A naive model of play was developed by separating each stage of the actions
taken by players in the client-side app, and separating them into individual
procedures. 

To facilitate the retrieval of information pertinent to a simulation in an
applied aspect, the model was written so as to contain simulation state as
mutable function arguments. The model was written as a workflow, and state of
workflow execution was separated into three components: the actor that a
function invocation (or ``step'') represents activity from; the context of that
step in the execution of a workflow; and the context of that workflow's
execution in a broader environment. Incidentally, we found this structure to
allow a flexible and natural implementation of a procedural simulation, which
should translate easily to existing simulation frameworks such as
SimPy\cite{simpy_intro}:

\begin{description}
  \item[Actor ---] allows the function to identify the actor performing the activity
    defined by the function. This argument is any object uniquely identifying an
    actor.
  \item[Context ---] allows the function to determine details of the current
    thread of work being undertaken by the actor. This is necessary because in
    some simulations, the same actor might pause and resume multiple occurrences
    of the same activity --- for example, they might concurrently play three
    different matches in RPGLite. As a result, it is necessary to understand the
    context of the action being performed by the actor in question. This
    argument can be any object uniquely identifying the context of a piece of
    work, but should be mutable (such as a class or dictionary-like object) to
    permit the communication of information across invocations of different
    action-representing functions.
  \item[Environment ---] an actor's actions are often determined by the global
    environment they act within. There may be ancillary details to the
    actor's actions and the context of their particular thread of work which
    they are undertaken within which are used to determine behaviour, such
    as a landscape they traverse or other actors they might choose to
    interact with. Because all actors share access to a global environment,
    this also provides a message passing space, or a space where actors can
    set values and flags other actors might look to, should those details be
    more general than their specific thread of work at a given point in time.
    \footnote{This is different to environments in some other simulation frameworks, such
    as SimPy\cite{simpy_documentation}, where the environment controls scheduling and
    execution: this structure imposes no constraints such as models of time, and
    anticipates that any such functionality should be implemented by the
    programmer. However, an environment such as SimPy's might satisfy a programmer's needs
    when using this particular pattern.}
\end{description}

Each simulation step receives these three arguments at a minimum. Because steps
of the model are functions, and therefore valid join points, aspects applied to
these have access to the entire state of the simulation.

The naive model of RPGLite follows a simple workflow mimicking player
interaction with the client-side application used by real-world players.
A graphical representation is provided in \cref{fig:naive_model}. \inline{Position this figure properly on the page.}
\inline{Maybe reword? Pretty verbose.} The model it describes produces synthetic data.
It does so by simulating players interacting with each other in a broader
RPGLite ecosystem. The large number of players is important: future behavioural
variations introduce behaviours which guide future actions based on past
experiences. Non-determinism early in the model can therefore cause different
players to act in different ways. Simulating many players allows the system to
represent a wide variety of early experiences, as would occur to real-world
players, too. As the aspects being woven simulate learning, early experiences
which cause players to learn maladaptive strategies --- or simply strategies
less optimal than those learned by their peers --- should later contrast against
winning strategies, so that players with less useful early inferences can learn
from players who play more optimally.

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{50_optimisation_with_aspects/diagrams/naive_model.png}
  \caption{A flowchart diagramming a simple model of RPGLite play, without
  aspects applied.}
  \label{fig:naive_model}
\end{figure}


\inline{Consider changing \cref{fig:naive_model} to only include details about
the model of the game itself, leaving the steps about data analysis to the
later aspect-applied version (which is the real experiment).}
\inline{Move \cref{fig:naive_model} to .svg for fidelity}
The stages of the naive model as laid out map to those encountered by real-world
players. Two randomly-selected players repeatedly select characters to play
(from the pool of 8 characters available in the real-world game), and a player
is chosen to play first at random. That player selects a random valid move to
make.\footnote{Many simulated decisions are random; this is because the model is
designed to be naive, so it avoids informed decisions where possible. Informed
decisions are expected to be woven later as aspects.} The active player alternates, and the process repeats, until
such time as an active player starts their turn with both of their characters
fully depleted of health. The player with remaining characters is the victor,
and another game is started by picking random players and starting a game
between them, until a predetermined number of games has been played.

After a sufficient number of games are played, analysis of the various datasets
collected can begin, although this is discussed in more detail in
\cref{sec:optimisation_with_aspects_experimental_design}.




\section{Experimental Design}\label{sec:optimisation_with_aspects_experimental_introduction}

% Having discussed the naive model above, this section describes how we'll apply
% aspects to set up an experiment, simulating players with variations to
% controlled simulations, and how such an experiment answers our research
% question.

% This likely won't need any subsections: we've already laid out the groundwork
% above as to what's involved technically, so this is statistical, explanation
% of our control, our model under test, and how they'll be compared in a
% rigorous and scientifically appropriate manner.

% However, this \emph{should} lay out the rationale behind simulating learning
% with our aspects; we'll discuss how our datasets are compared here, and how we
% measure similarity, which is done by proportion of classes picked over time.
% There are statistical and methodological requirements at play here --- we
% needed something we could compare in a statistically significant manner ---
% but also, we needed something which the dataset we had could support analysis
% of. We only had a few players with statistically significant numbers of games
% played. Character choice seemed a reasonable way to go, because the metagame
% introduces specific character combinations which are optimal, and we'd expect
% players to learn those over time. Players \emph{might} get stuck in local
% minima, but learning aspects would too, so simulated player data should still
% reflect that. Also, the choice of an ideal team composition is a
% well-understood aspect of metagame design \inline{Is team composition in
% metagame design something there's also literature on, or is this only within
% the gaming industry?}, so we can imagine players optimising team composition
% in RPGLite like they would in other trading card or RPG games.

The naive model above describes a simulation of RPGLite itself; however, the
models exists to support investigation into research questions, and cannot do
this alone. To answer our research questions, the model must be augmented so as
to represent real-world play. This section describes the modifications made to
the naive model (through aspects applied by PyDySoFu) and how data from those
simulations can be analysed to arrive at answers to our research questions. 

The questions these simulations seek to answer are:

\begin{enumerate}
  \item Can we fit model details per-player to get realistic player behaviour?
  \item Can we cluster based on accuracy of different models for each player?
  \item Can we generate predictive data for unknown models from known ones?
\end{enumerate}
% \begin{figure}[H]
% \begin{researchquestion}
%     Can we fit model details per-player to get realistic player behaviour?
% \end{researchquestion}
% \caption*{Research question 1}
% \label{RQ1_experimental_chap}
% \end{figure}
% \begin{figure}[H]
% \begin{researchquestion}
%     Can we cluster based on accuracy of different models for each player?
% \end{researchquestion}
% \caption*{Research question 2}
% \label{RQ1_experimental_chap}
% \end{figure}
% \begin{figure}[H]
% \begin{researchquestion}
%   Can we generate predictive data for unknown models from known ones?
% \end{researchquestion}
% \caption*{Research question 3}
% \label{RQ1_experimental_chap}
% \end{figure}

\inline{These RQs are taken from an early outline of a thesis structure. Maybe they need rewording?}
To investigate these, we produce models of learning which can be applied to the
naive model to augment player behaviour. Simulated players will have their
behaviour augmented in relation to the character pairs they choose to play.
Real-world players could reasonably be expected to choose character pairs which
are stronger together over time. In addition, it is possible to calculate
objectively optimal character pair selections in RPGLite\inline{Cite William's
thesis as a source for objectively optimal character pair selections.};
therefore, players should be expected to gravitate toward more optimal character
pairs and away from poorer choices as they become more experienced in the game.

A few facets of gameplay are expected to be learned by players over time, and
would theoretically also be suitable objects of simulated players' learning. One
analog to character pair selection could be move selection: players would be
expected to make increasingly optimal moves as they play. However, data can be
muddied by players understanding the optimal use of some characters' moves
better than others, as different characters invite different styles of play.
Small changes to game states (the opposing team's composition, amount of health
remaining, opponent play styles) could influence player behaviour also.
Fundamentally, the state space of moves to be made and scenarios in which to
make those moves is extremely large, making simulation computationally
expensive. By comparison, character selection happens before gameplay starts,
eliminating in-game factors which might influence player decisions.

Modelling the learning of character pair selection allows for modelling of
players learning the metagame, rather than the game itself. Modelling learning
of the metagame allows us to model players learning about the game and other
players' interactions with it, rather than learning the game itself. An example
of the distinction is the difference between learning how optimally make moves
with a Barbarian in a team, and learning the mistakes other players commonly
make when playing a Barbarian to exploit their weakness. As RPGLite is
``solvable'' --- there is a provably correct way to play the game --- players
picking sub-optimal character pairs can be expected to observe that they are
frequently beaten by better ones, increasingly favour pairings they identify as
successful, and so converge on strong character pairs. Convergence en-masse
would indicate a stable metagame. This was observed in practice in real-world
RPGLite play~\cite{kavanagh2021gameplay}. However, while players made fewer
mistakes over time when playing RPGLite, the average cost of a move to their
probability of winning increased after many games (though decreased after a
few).~\cite{kavanagh2021gameplay}. Player behaviour which converges on provably
optimal play is simpler to represent than players' initial improvement followed
by a seeming loss of performance. RPGLite Character selection is therefore a
more convenient metric to model players' interaction with than move selection,
as it presents a smaller state space for simulated players to explore while also
providing a simpler expected end state for those simulated players to converge
to.

Models of learning are therefore applied to players' character selections. Our
primary goal in applying models of learning is to demonstrate whether players
can be accurately modelled by augmenting a naive model to represent them in
particular, thereby answering the first research question. Different real-world
players are expected to exhibit different styles of learning; thus, multiple
models of learning will be applied. Different players might also learn
differently, but in the same style; for example, two players might exhibit
similar biases, but one could be quicker to learn from experience or another
more cautious in the application of new knowledge.

To identify models of learning and parameters for those models which most
realistically represent real-world players, we look to optimise the parameters
for each model, for each player, by running multiple simulations of players
learning in a particular manner (with particular parameters), identifying their
preferred character pairings, and calculating the similarity of the simulated
character pairings to that of a player in the real world. By doing so, we can
anneal to a parameter which represents the optimally realistic model of a player
learning in a given style. If the data produced by this optimally parameterised
model of learning is not similar to empirically sourced data with statistical
significance, we determine that the model of learning applied does not represent
how a player learned in the real world: even the closest dataset the model
produced fit its target dataset poorly. However, if a parameter can be found for
which the model reliably produces character pair preferences which align with
the real-world players' with statistical significance, then the model can be
said to realistically represent that player's learning of the character pair
metagame.

This section will first discuss models of learning generally in
\cref{subsec:models_of_learning_discussed}, and will explain how aspects
implementing these models can be produced in
\cref{sec:optimisation_with_aspects_aspectsdeveloped}. The strategy used to
implement these models of learning is discussed in
\cref{subsec:defining_our_models_of_learning}. The design of experiments
investigating the aforementioned research questions by applying these aspects is
then described in \cref{sec:optimisation_with_aspects_experimental_design}.
\inline{Rearrange either this paragraph of the sections it refers to so they're in order / make sense. At time of writing they refer to 6.3.1, then 6.4, then 6.3.2, then 6.5\ldots{}!}


\subsection{Models of Learning}\label{subsec:models_of_learning_discussed}
Different people learn in different ways. Indeed, no universally-accepted
definition of learning appears to exist. This is presumably because it is
convenient to define what it means to learn differently in the context of
different pieces of work. Cognitive models of learning can be useful when
considering mental processes specifically, for example, whereas functional
models of learning could lend a more empirically applicable perspective. What it
means to learn is clearly outwith the scope of this thesis; however, our
experiments will include models of learning. To justify our model, we consider a
functional approach to learning, as considering learning in this way appears
more closely linked to the empirically focused work of modelling real-world
behaviour than alternatives.

\citeauthor{lachman1997learning} identify\cite{lachman1997learning} that
standard definitions of learning along the lines of, ``Learning refers to a
relatively permanent change in behavior as a result of practice or experience''
have practical shortcomings such as a focus on behavioural change (as learning
may not change behaviour) or conflating learning's process and its product (the
process by which we learn is not obviously identical to its result, of which
behavioural change is an example). They suggest learning might be better defined
as:

\begin{displayquote}
[\ldots{}] the process by which a relatively stable modification in
stimulus-response relations is developed as a consequence of functional
environmental interaction via the senses [\ldots{}] rather than as a consequence
of mere biological growth and development~\cite{lachman1997learning}.
\end{displayquote}

They note that their definition distinguishes learning from phenomena such as
injury, changes to one's maturity, or sensory adaptation, incorporates
stimulus-response relationships the research community consider as learned, and
differentiates learning's process and product. Their model is inherently
functional, making it useful for the purposes of simulation and modelling,
although they offer only a definition of learning and a brief comparison to
the standard textbook definition they introduce. The work presented is not
intended to demonstrate its improved model of learning empirically, only to
discuss its semantic merit. However, the models proposed in this thesis require
only a theoretically informed, sound basis for their model of learning, and a
lack of empirical justification is not a barrier to the relevance of the model
\citeauthor{lachman1997learning} have proposed.

\citeauthor{de2013learning} propose a functional definition of learning which is
primarily concerned with providing a definition of learning which is both
accurate and useful for the purposes of cognitive learning
research~\cite{de2013learning}. Doing so attempts to provide a model around
which some concensus can be reached; learning is a central concept in
psychology, and they see their definition as supportive of cognitive work. They
introduce their definition as follows:

\begin{displayquote}
Our definition consists of three components: (1) changes in the behavior of the
organism, (2) a regularity in the environment of the organism, and (3) a causal
relation between the regularity in the environment and the changes in behavior
of the organism.
\end{displayquote}

This model of learning contains more nuance than the ``textbook definitions'' of
learning they paraphrase as, ``a change in behavior that is due to experience'',
but does not stray far from the core concept: some environmental stimulus
impacts behaviour in a causal fashion. Their introduction of ``regularity'' to
their definition refers to the presence of the stimulus with some form of
repetition, whether this be multiple instances of a stimulus at different times,
or the same stimulus occurring concurrently. \citeauthor{de2013learning} explain
that such a model is straightforward without the sweeping inclusivity of the
simple model mentioned earlier, and is easily verified (although, as in the work
of \citeauthor{lachman1997learning}~\cite{lachman1997learning}, empirical
verification is omitted in favour of semantic analysis).

Aside from other benefits more particular to their research community, these
benefits are especially useful from the perspective of modelling learning in our
case. A simple, functional definition can be captured in a software model, and
introduces few opportunities for misunderstanding or mis-application. It also
introduces helpful concepts --- such as regularity and causality --- which the
other definitions discussed do not. For the purposes of this thesis, we
therefore adopt this definition as a basis for our model of learning.

\subsection{Modelling Learning in RPGLite}\label{subsec:defining_our_models_of_learning}
% Describe our model of learning. Confidence introduces regularity, priors
% introduce causal relationship, behavioural change is in selection of character
% pairs.

We use \citeauthor{de2013learning}'s definition of
learning~\cite{de2013learning} to arrive at a model of learning which is
encodable in aspects that can be applied to our naive model of RPGLite. We are
interested in modelling players learning a preference for character pairs over
time. The model should therefore account for: how player behaviour is influenced
in accordance with their learning, in line with the definition's first
criterion; repetition of experience in successive games influencing the
direction of a player's learning, in accordance with the definition's second
criterion; and do so in a causal manner, in accordance with the definition's
third criterion. We therefore look to model a causal relationship between a
player's observation of successful character pairs and their future choices of
character pairs.

To fulfil these requirements, a model might draw on previously successful
character pairs to determine future ones. There are many ways in which this
could be done. For example, we could model learning as consistently playing the
character pair which most recently was observed to win a game. Any game ending
naturally determines a winning pair, and we can select this pair when playing
future games, until a different pair is observed to win instead. However, this
does not align with our expectations around how players \emph{would} engage with
a game in the real world. Having a strategy one is confident in and being
unlucky with the game's random nature is unlikely to deter a player from what
they believe is ideal. Indeed, we can expect players to understand
that perfect play might not be winning play: in some games, the right moves
might not lead to a successful outcome due to moves randomly missing opponent
characters. Equally, players may take time to become confident in a strategy; we
would expect a player to explore character choices before settling on a
preferred pair early in their experience, and would expect very experienced
players to choose characters based on what they have learned, rather than
continuing to explore options for which they have sufficient information to
reason about. We can infer that:

\begin{itemize}
  \item There are scenarios where players can be expected to observe wins/losses
  without incurring behavioural change.
  \item Players' confidence in what they have learned can affect their
  inclination to draw on what they learn when making decisions.
  \item What players learn in successive games would have a small impact in
  their early experiences, but an increasingly significant impact proportional
  to their experience in the game.
\end{itemize}

\inline{We've set the stage to explain and justify our own models of learning. Let's go!}


\section{Aspects Applied}\label{sec:optimisation_with_aspects_aspectsdeveloped}

% Players can be expected to select stronger characters as they understand
% gameplay more. Aspects were therefore developed to track player experience with
% characters. As players became more familiar with the characters they play, we
% can hypothesise that they will better understand how to play with those
% characters, and more often select characters they have success with. 



% \inline{Write about \emph{both} aspects so as to answer the hypothesis : Can
% aspects be used to generate models of alternative behaviours?}

% The aim of this experiment is to investigate whether a model with
% aspect-oriented behavioural variation can be realistic; the experiment therefore
% requires the development of aspects representing plausibly realistic behavioural
% variation. Traces from simulations affected by these aspects should produce
% synthetic data which can be compared to real-world data and to naive data,
% enabling the measurement of the datasets' similarity, as discussed
% in~\cref{sec:optimisation_with_aspects_aspectsdeveloped}. 

% To demonstrate that simulated players are plausibly realistic, and
% that a simulation's realism can be improved by the addition of behavioural
% variance as a cross-cutting concern, naive player behaviour is augmented by
% applying aspects which represent learning. Two methods of learning RPGLite's
% metagame were produced; this section will detail both.

% In each model of learning, players are assumed to have a draw towards choosing
% to play some characters, and less of a draw to others. This draw is informed by
% whether players have reason to believe they'll be successful after choosing a
% given character; players' future decisions are informed by the outcomes of their
% previous ones. The models of leaning presented in this section are
% differentiated by the manner in which future decisions are informed.

Having a naive model of player interaction in RPGLite allows for the generation
of a control dataset, which can be compared to aspect-applied datasets to
examine whether the aspect-applied models are provably ``closer'' to
empirically-sourced data than the naive dataset\footnote{``Closer'' here refers
to a similarity measurement which we will define later in this chapter.}. To
generate the experimental dataset, the naive model producing our control is
augmented through the application of aspects. These aspects fulfil different
functions, and can broadly by grouped into three categories:

\begin{enumerate}
  \item Aspects implementing behavioural models, changing the behaviour of
  simulated players;
  \item Aspects instrumenting the naive model to perform observations necessary
  for the implementation of behavioural models (such as models of learning) on
  the naive model;
  \item Aspects altering the behaviour of modelled players to simplify
  experimental observation, and to handle exceptions introduced by changes
  within the aspect-applied model.
\end{enumerate}

The first set of aspects implement the behavioural change we anticipate will
produce datasets closer in similarity to empirically sourced data than that
sourced by the naive model. The second set lays the foundation for applying
these changes. The third applies behavioural changes which experimental
observations require. Necessary changes unrelated to our models of learning will
first be explained in \cref{subsec:aspects_improving_model}, followed by an
introduction of foundational observations for our models of learning in
\cref{subsec:aspects_modelling_learning}. Finally, the models of learning built
on those foundations are introduced in
\cref{subsec:aspects_instrumenting_model}.
\inline{The ordering of this explanation of different uses of aspects is confusing; once the aspects are explained individually, reorder the sections, rework the introduction to the structure of this section, and ensure the outline of the section reflects the changes made.}

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{50_optimisation_with_aspects/diagrams/aspect_applied_model.png}
  \caption{A flowchart describing a simulated game of RPGLite, and all aspects woven into the game to implement the various models of learning. Some aspects should not be woven together in the same experimental run, as they implement different models of learning.}
  \label{fig:all_aspects_applied}
\end{figure}

A diagram of a game of RPGLite with all possible aspects
applied\footnote{Including aspects which should not be woven in the same
experimental run: some aspects implement different models of learning and are
therefore conceptually incompatible.} is
presented in \cref{fig:all_aspects_applied}, by way of high-level overview of
the aspects this section introduces.

\subsection{Aspects for model improvement}\label{subsec:aspects_improving_model}

\subsubsection{Ensuring the Best Move is Played}\label{subsubsec:ensure_best_move}

% We make sure players always make the best moves, because it reduces the space of
% situations where randomness can skew our results. An analysis of how well this
% reflects real-world player interactions can be found in \inline{Cite William's
% thesis for realism of players making perfect moves.}

As discussed in \cref{sec:optimisation_with_aspects_experimental_introduction},
the goal within this experiment is to build a model of players' learning of
character selection rather than move selection. However, randomly selected moves
are liable to place players in unrealistically weak positions, as players are
unlikely to make obviously poor moves such as skipping a turn with no clear
reason. It would be unexpected to see true randomness in players' moves. This is
a concern for the modelling of players' character selection, because the model
of learning defined requires a causal relationship between what is observed (in
this case characters which most reliably win games) and behavioural change
(players choosing character pairs proportionally to their estimated chance of
winning a game); if selecting random moves cause simulated players to lose games
when they would have realistically won them, this would affect character
selection by definition.

Character selection and move selection are therefore somewhat linked. However,
move selection is most frequently optimal: in the majority of cases real-world
players chose the best move available to them, as analysed by \citeauthor{kavanagh2021gameplay}~\cite{kavanagh2021gameplay}~:

\begin{displayquote}
  [\ldots{}] the majority of actions taken were optimal, with a cost of 0.0. In
  total 73\% of the player’s season 1 actions and 77.8\% of their season 2
  actions were optimal.\footnote{Different seasons of RPGLite are discussed in
  more depth in \inline{Make a reference to the chapter(s) where I explain
  different seasons of RPGLite.}}
\end{displayquote}

Therefore, a naive model of move selection which represents real-world move
choices in \(\frac{3}{4}\) of cases is to select the best move at every
opportunity. We therefore apply an aspect to the function responsible for move
selection which performs a lookup on the dataset of action costs defined by
\citeauthor{kavanagh2021gameplay}~\cite{kavanagh2021gameplay}, and select the
known-optimal move in every case.

A model of move selection more closely aligned with expectations of player
behaviour is beyond the scope of this thesis: a demonstration that models of
both move selection and character selection can be optimised concurrently to
arrive at a realistic model of empirical play with multiple aspectually applied
models of behavioural variance invites itself as future work.
\inline{Do I need code snippets for notes on aspects?}


\subsubsection{Handle Game States with no Viable Moves}

% Using lookup tables provided by William's thesis (cite here!) means
% crossreferencing the game states in our simulation against game states in
% William's models. Turned out there were states they didn't track because it
% was not possible to make any move at all that could win, so the game's a
% foregone conclusion in those states. Because the aspect in
% \cref{subsubsec:ensure_best_move} aspect reads states from lookup tables which
% might not contain those states, our model can throw exceptions when performing
% lookups! Handle those scenarios and treat as an unwinnable game for the
% appropriate player.




% TODO: Section / subsection for observational aspects
\subsection{Aspects for Instrumentation}\label{subsec:aspects_instrumenting_model}

\subsubsection{Update Model of Confidence}

\subsubsection{Record Prior Distribution of Character Preferences}
\inline{Looks like aspect recording prior distribution might be applied to data
generation; figure out how to fit it into \cref{fig:all_aspects_applied}.}

\subsubsection{Record Character Choices}

\subsubsection{Track Outcomes of Games}

\subsubsection{Record Winning Pair seen by Players on Game End}


% TODO: Section / subsection for models of learning
\subsection{Aspects Implementing Models of Learning}\cref{subsec:aspects_modelling_learning}

\subsubsection{Character Selection from prior distribution}

\subsubsection{Character Selection using confidence sigmoid}

\subsubsection{Character Selection exhibiting hyperbolic decay}



\inline{Why didn't we make a bayesian model of learning? Should we have? Would this be difficult at all?}

\subsection{Simple Model of Learning}\label{subsec:optimisation_with_aspects_basiclearningaspect}

\inline{Describe probability updates by way of a simple PMF defined by previous outcomes}




\subsection{Modelling Bias with Hyperbolic Decay}\label{subsec:optimisation_with_aspects_hyperbolicdecay}

\inline{Find citations explaining hyperbolic decay}

\inline{Describe probability updates affected by a hyperbolic decay bias}


\section{Experimental Design}\label{sec:optimisation_with_aspects_experimental_design}

Specifics of how we intend to analyse our data, leading on from the brief
discussion in \cref{sec:optimisation_with_aspects_experimental_introduction}.
\inline{Discuss specifics of how we intend to analyse data, rather than high-level experimental overview presented in earlier chapters}



\section{Experimental Results}\label{sec:optimisation_with_aspects_experimental_results}

Presentation of the results owing from the experiment as described in
\cref{sec:optimisation_with_aspects_experimental_design}, and evaluation of the
research question with respect to these findings.

Again, no subsec likely required here.

\section{Discussion}\label{sec:optimisation_with_aspects_discussion}

A closing discussion on what we found, and how the research question was
answered.